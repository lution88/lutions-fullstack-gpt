{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMChain\n",
    "LLM chain 은 off-the-shelf chain 으로 off-the-shelf 는 general 일반적인 목적을 가진 chain 을 의미한다.  \n",
    "langchain 에 아주 많고 아주 유용하다.\n",
    "\n",
    "하지만 우리가 스스로 무언가를 만들어볼 때 off-the-shelf chain 보다 우리가 직접 커스텀해서 만든 chain 을 활용하기를 선호할거다.\n",
    "\n",
    "off-the-shelf chain 은 빠르게 시작할 수 있어서 좋긴 하지만 프레임워크를 다루느라 머리 싸매거나  \n",
    "off-the-shelf chain을 커스텀하기보다 직접 만들고 싶을 때 이전에 배운 것처럼 langchain expression 언어를 활용해서 우리의 것을 만들 수 있다.\n",
    "\n",
    "그럼 off-the-shelf chain 은 어떻게 쓰냐면 다음과 같다.\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "```\n",
    "LLMChain 은 아주 일반적인 것이다.\n",
    "\n",
    "우리가 가진 memory 를 LLM Chain 안으로 넣어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=80,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interaction - 사용자와 AI 사이의 대화(질문과 답변)입니다\n",
    "\n",
    "예:  \n",
    "- 사용자: \"오늘 날씨 어때?\" (토큰 4개)  \n",
    "- AI: \"맑고 화창해요.\" (토큰 5개)  \n",
    "위 대화의 총 토큰 수는 9개입니다.  \n",
    "\n",
    "Interaction의 토큰 수가 많아지면 메모리가 커지면서 비용과 처리 시간이 증가합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory 는 ConversationSummaryBufferMemory 를 사용해 본다.\n",
    "\n",
    "ConversationSummaryBufferMemory 는 interaction 들을 기본적으로 가지고 있는 conversation class 이다.\n",
    " \n",
    "그리고 interaction 의 토큰 수가(위의 경우) 80개보다 많으면 가장 오래된 interaction 을 요약해준다.\n",
    "\n",
    "최신 내용을 그대로 유지하고 대화 기록을 요약하기 시작할거다.\n",
    "\n",
    "그럼 우리가 원하는 memory 를 사용할 수 있다.\n",
    "\n",
    "그럼 chain 을 만들어 보자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Lution, nice to meet you! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm, memory=memory, prompt=PromptTemplate.from_template(\"{question}\")\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is lution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에 한 가지 사실을 더 추가해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant and bustling city with a rich history and culture. There are so many things to see and do in Seoul, from exploring ancient palaces and temples to enjoying delicious Korean cuisine and shopping in trendy neighborhoods. What do you enjoy most about living in Seoul?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in seoul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 물음에 대한 질문을 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기억하지 못한다.\n",
    "\n",
    "chain 을 debuging 해보자. langchain 은 verbose 라는 좋은 속성을 가지고 있다.  \n",
    "\n",
    "이 값을 chain 에 전달하면 chain 이 실행했을 때 chain 의 프롬프트 로그들을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mMy name is lution\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Lution, nice to meet you! How can I assist you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is lution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI live in seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Seoul is a vibrant and bustling city with a rich history and culture. There are so many things to see and do in Seoul, from exploring ancient palaces and temples to enjoying delicious Korean cuisine and shopping in trendy neighborhoods. What do you enjoy most about living in Seoul?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "chain.predict(question=\"What is my name?\")\n",
    "```\n",
    "\"what is my name?\" 이라고 물으면 프롬프트도 \"what is my name?\" 이라고 한다.\n",
    "\n",
    "여기서 보면 대화의 내역이 프롬프트에 계속 추가되진 않는다.\n",
    "\n",
    "이게 우리가 해야할 일이다.\n",
    "\n",
    "우리가 원하는 어떤 방식으로라도 프롬프트에게 대화 기록을 추가해 줘야 한다.\n",
    "\n",
    "그렇지 않으면 우리가 대화 내역을 말해준 적이 없기 떄문에 이전 대화에 대해서는 다 까먹게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 재밌는 건 memory 는 계속 업데이트 되고 있다는 사실이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"System: Lution introduces themselves and mentions they live in Seoul. The AI responds enthusiastically, highlighting the vibrant and bustling nature of the city. It asks Lution what they enjoy most about living in Seoul. The human asks the AI for their name, and after revealing it, the AI greets Lution and offers assistance. The AI expresses admiration for Seoul's rich history and culture, mentioning the variety of activities and experiences the city has to offer.\\nHuman: What is my name?\\nAI: I'm sorry, I do not have access to personal information such as your name.\"}\n"
     ]
    }
   ],
   "source": [
    "prev_memory = memory.load_memory_variables({})\n",
    "print(prev_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 보듯, 우리의 대화를 요약하는 건 이미 잘 동작하고 있다. 자체적으로 업데이트도 하면서.\n",
    " \n",
    "문제는 이것들은 프롬프트에 포함하지 않는다는 것.\n",
    "\n",
    "프롬프트에 전달되어야 하는 대화 내용이 LLM 에게 전달되지 않고 지금 프롬프트는 우리에게 혹은 LLM 에게 question 만 주고 있다.\n",
    "\n",
    "메모리에 좀 더 큰 토큰제한을 걸어보고, 프롬프트도 새로 만들어보자.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI 가 우리의 대화 기록을 기억하여 question 을 완성할 수 있도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "{'history': \"System: Lution introduces themselves and mentions they live in Seoul. The AI responds enthusiastically, highlighting the vibrant and bustling nature of the city. It asks Lution what they enjoy most about living in Seoul. The human asks the AI for their name, and after revealing it, the AI greets Lution and offers assistance. The AI expresses admiration for Seoul's rich history and culture, mentioning the variety of activities and experiences the city has to offer.\\nHuman: What is my name?\\nAI: I'm sorry, I do not have access to personal information such as your name.\"}\n",
    "```\n",
    "보다시피 history 와 memory 가 human 과 LLM 의 인풋 아웃풋을 기반으로 업데이트 되고 있다.\n",
    "\n",
    "이제 우리는 이 conversation memory class (ConversationSummaryBufferMemory)에게 템플릿 안에 콘텐츠를 넣으라고 얘기를 해줘야 한다.\n",
    "\n",
    "이건 memory 에 memory_key 를 불러서 chat_history(위에서 설정한)라고 말해주기만 하면 된다.\n",
    "\n",
    "memory.load_memory_variables({}) 같은 것들은 안해도 된다.\n",
    "\n",
    "단지 conversation memory class 에게 memory key 라는 속성을 불러주기만 하면 된다.\n",
    "\n",
    "* memory_key: template 안에 memory 가 history 를 저장하도록 한 곳을 적어준다. <br>즉 memory_key 와 template 의 메모리 저장 변수명은 동일해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory 는 template 안에 대화 기록을 저장하는 공간을 찾을거고, 자동으로 그 메모리의 기록을 여기에 담는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human: My name is lution\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello lution! How can I assist you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is lution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is lution\n",
      "AI: Hello lution! How can I assist you today?\n",
      "    Human: I live in seoul\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in seoul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"나는 서울에 산다\" 를 실행해본다.\n",
    "\n",
    "그럼 보다시피 프롬프트에 기록이 남겨져 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is lution\n",
      "AI: Hello lution! How can I assist you today?\n",
      "Human: I live in seoul\n",
      "AI: That's great to hear! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?\n",
      "    Human: What is my name?\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is lution.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 memory 를 AI 에게 전달했다.\n",
    "\n",
    "요약하자면, 우리는 그저 메모리를 위한 공간을 우리 프롬프트 템플릿 안에 만들기만 하면 된다.\n",
    "\n",
    "```python\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "{chat_history} 여기에 들어가는 변수의 이름은 아무거나 해도 상관없다. \n",
    "```\n",
    "\n",
    "우린 프롬프트 템플릿에 memory 를 위한 공간을 만들고, 우리가 사용하고 있는 memory class 에게 \n",
    "\n",
    "history 를 넣을 곳을 알려주기만 하면 된다.(memory_key)\n",
    "\n",
    "여기까지가 우리가 memory 에 추가하고 싶을때, 문자열 형태로 된 프롬프트 템플릿에 대화 기록을 추가하고 싶을 때 하는 일이였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "다음으로는 같은 대화기록을 추가하는 방식인데 메세지를 기반으로 한 사람과 AI의 대화 기록을 추가하는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 기반 메세지의 memory 는 쉬운 것 같다?\n",
    "\n",
    "기억해야할 건 memory class 가 memory 를 두 가지 방식으로 출력할 수 있다는 걸 알아야 한다.\n",
    "\n",
    "출력방식으로는 문자열 형태일 수도 있고, message 형태일 수도 있다.\n",
    "\n",
    "예를 들어 .load_memory_variables 를 실행해보면\n",
    "```python\n",
    "memory.load_memory_variables({}) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: My name is lution\\nAI: Hello lution! How can I assist you today?\\nHuman: I live in seoul\\nAI: That's great to hear! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know or discuss about Seoul?\\nHuman: What is my name?\\nAI: Your name is lution.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그냥 텍스트가 나오는 걸 확인할 수 있다.\n",
    "\n",
    "프롬프트에 표시되는 방식은 그냥 텍스트일 뿐이다.\n",
    "\n",
    "이제 대화 기반의 채팅으로 사용하고 싶다면 이걸 바꿔줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 우리는 memory 를 먼저 바꿔준다.\n",
    "\n",
    "return_messages=True 를 추가해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이건 문자열로 바꾸지 말고 실제 메세지로 바꿔달라는 걸 의미한다.\n",
    "\n",
    "사람 메세지든, AI 메세지든, 시스템 메세지든 실제 message 클래스로 바꿔달라고 말이야"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 이제 문자열 기반 템플릿 대신 ChatPromptTemplte 을 불러오자.\n",
    "\n",
    "기본 문자열 기반 템플릿인 template 를 지우고 프롬프트를 생성해서 다음과 같이 작성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 이 question 에 우리는 어떻게 대화 기록을 넣어둘 수 있을까?\n",
    "\n",
    "대화 기록에는 엄청 많은 human message 와 ai message 들이 있을 것이고 \n",
    "\n",
    "우리가 ConversationSummaryBufferMemory 로부터 요약본을 받아올 때 system 메세지도 추가될 예정이다.\n",
    "\n",
    "그럼 이 많은 것들을 위한 공간을 어떻게 만들 수 있을까??\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정답은 MessagesPlaceholder 를 사용하는 것이다.\n",
    "\n",
    "MessagesPlaceholder 는 prompt 안에 선언해주면 메세지의 양과 제한없는 양의 메세지를 가질 수 있다.\n",
    "\n",
    "MessagesPlaceholder 에는 history 를 넣을 곳을 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 우리의 conversationSummaryBufferMemory 는 그 기록들에서 메세지들을 가져와서 모든 메세지 기록들로 MessagesPlaceholder 를 채우게 된다.\n",
    "\n",
    "말했듯이 ConversationSummaryBufferMemory 가 AI, Human, System 메세지를 줄거고, \n",
    "\n",
    "우리는 그게 얼마나 많은지 알 수 없기에 프롬프트 안에 MessagesPlaceholder 를 불렀다.\n",
    "\n",
    "MessagesPlaceholder 의 역할은 메세지가 얼마나 많고 누구에게로부터 왔는지 모르지만 \n",
    "\n",
    "이 MessagesPlaceholder 가 memory class(여기서는 ConversationSummaryBufferMemory)로 대체될거다.\n",
    "\n",
    "이제 prompt 를 chain 에 넣어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is lution\n",
      "AI: Hello lution! How can I assist you today?\n",
      "Human: My name is lution2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello lution2! How can I assist you today?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"My name is lution2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is lution\n",
      "AI: Hello lution! How can I assist you today?\n",
      "Human: My name is lution2\n",
      "AI: Hello lution2! How can I assist you today?\n",
      "Human: I live in incheon\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to know! Is there anything specific you would like to know or talk about regarding Incheon?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in incheon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is lution\n",
      "AI: Hello lution! How can I assist you today?\n",
      "Human: My name is lution2\n",
      "AI: Hello lution2! How can I assist you today?\n",
      "Human: I live in incheon\n",
      "AI: That's great to know! Is there anything specific you would like to know or talk about regarding Incheon?\n",
      "Human: what is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is lution2. How can I assist you further today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "지금까지 우리는 메모리를 문자열기반 완성품들과 채팅 메세지 기반 완성품들에 넣는 방법을 배웠다.\n",
    "\n",
    "이제 우리는 수동으로 만들어진 chain 에 LCEL를 활용해서 어떻게 memory 를 추가할 수 있을지 배워볼거다.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
